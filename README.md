# Auto Documentation with n8n + LLM

Gera documenta√ß√£o em **Markdown** a partir de arquivos **.py** de um reposit√≥rio Git, usando um fluxo no **n8n** conectado a um **LLM** (Groq ou LM Studio).  

## üìå Vis√£o geral
- Clona um reposit√≥rio  
- L√™ todos os arquivos indicados no n√≥ **Ler arquivos de c√≥digo**
- Converte bin√°rios ‚Üí texto  
- Envia cada arquivo ao LLM com um prompt de documenta√ß√£o  
- Junta as respostas  
- Gera a documenta√ß√£o e salva na pasta indicada no √∫ltimo n√≥
> Workflow principal: `workflow.json`.

## üîß Funcionalidades
- Executa localmente via **Docker**
- Importa√ß√£o do `workflow.json` direto no n8n
- Uso do **LM Studio** (modelo de IA local via `host.docker.internal:<PORTA>`)
- Gera√ß√£o de documenta√ß√£o em Markdown (t√≠tulos, listas, trechos de c√≥digo)

## ‚úÖ Pr√©-requisitos
- **Docker** instalado
- **Git dentro do container do n8n** (para `git clone`)
- **LM Studio**
---

# üõ†Ô∏è Como correr na sua m√°quina (Windows)

### 1) Instalar o docker e criar o container do n8n (windows)
- Baixar e instalar o Docker Desktop
- P√°gina oficial (download): https://www.docker.com/ 
- Guia oficial de uso: https://docs.docker.com/
- A seguir, crie o container no terminal no seguinte formato: 
`docker run -it --name <CONTAINER_NAME> ^
  -v <HOST_PATH_TO_DATA>:/data ^
  -p <HOST_PORT>:5678 ^
  -e N8N_BASIC_AUTH_ACTIVE=true ^
  -e N8N_BASIC_AUTH_USER=<BASIC_AUTH_USER> ^
  -e N8N_BASIC_AUTH_PASSWORD=<BASIC_AUTH_PASSWORD> ^
  <IMAGE_NAME>`

### 2) Baixe o arquivo **workflow.json** que est√° neste reposit√≥rio

### 3) Acesse o n8n 

Abra: http://localhost:5679
  
### 4) Importar o workflow

No n8n, v√° em: **Create wokflow ‚Üí Import from file ‚Üí Selecione o** `workflow.json`.

# ‚öôÔ∏è Como configurar os n√≥s do fluxo do n8n

## 1) **Clonar reposit√≥rio** 

`rm -rf <TARGET_DIR> && git clone <REPO_URL> <TARGET_DIR>`

`<TARGET_DIR>`: a pasta de destino local onde o reposit√≥rio ser√° clonado.
Ex.: no container do n8n normalmente √© /data/repos.

`<REPO_URL>`: a URL do reposit√≥rio Git (HTTPS ou SSH).

Exemplo Completo:
`rm -rf /data/repos && git clone https://github.com/usuario/meu-repo.git /data/repos`

## 2) **Ler Arquivos do c√≥digo**

Percorre os arquivos na pasta indicada e pega os arquivos na linguagem escolhida.

Exemplo:
`/data/repos/**/*.py`

- `/data/repos/` ‚Üí pasta base onde a busca come√ßa.
- `**/` ‚Üí percorre recursivamente zero ou mais subpastas.
- `*.py` ‚Üí pega arquivos cujo nome termina em `py`

## 3) **AI Agent**

Neste n√≥ podem ser usados dois tipos de APIs:

### **API Externa**: 
Utiliza uma chave de API da OpenAI ou da Groq, obtida nas respetivas contas oficiais, para integrar o provedor externo ao teu fluxo conforme necess√°rio.
### **API Local**: 
### üì• Instalar o LM Studio

Baixe e instale para **Windows/macOS/Linux**:
- **LM Studio ‚Äî Download:** https://lmstudio.ai/download

### ‚¨áÔ∏è Baixar um modelo

No app, abra a aba de modelos (‚ÄúDiscover‚Äù), pesquise um modelo (ex.: llama-3.2-3b-instruct) clique em **Load**.  

### üîå Iniciar API local (OpenAI-compatible)

1. No LM Studio, v√° em **Developer / Start Server** (ou ‚ÄúLocal Server‚Äù).  

### üîó Conectar no n8n

Use o n√≥ **OpenAI Chat Model** (ou **OpenAI Compatible Chat**) e crie uma credencial com:
- **API Key:** `lm-studio`
- **Base URL:** `http://localhost:1234/v1` (ou `http://host.docker.internal:1234/v1` se o n8n estiver correndo em um container no Docker)
- **Model:** exatamente o nome exibido no LM Studio (ex.: `llama-3.2-3b-instruct`)

### 4) Ap√≥s isto, basta clicar em *Execute workflow* no n8n e a documenta√ß√£o ser√° gerada e guardada na pasta indicada no n√≥ **Salvar DOCUMENTATION** 







