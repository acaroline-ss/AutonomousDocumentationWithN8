# Auto Documentation with n8n + LLM

Gera documenta√ß√£o em **Markdown** a partir de arquivos **.py** de um reposit√≥rio Git, usando um fluxo no **n8n** conectado a um **LLM** (Groq ou LM Studio).  
**Sa√≠da padr√£o:** `DOCUMENTATION.md` dentro de `/data/repos`.

## üìå Vis√£o geral
- Clona um reposit√≥rio  
- L√™ todos os `.py`  
- Converte bin√°rios ‚Üí texto  
- Envia cada arquivo ao LLM com um prompt de documenta√ß√£o  
- Junta as respostas  
- Salva em `DOCUMENTATION.md`  

> Workflow principal: `workflow.json`.

## üîß Funcionalidades
- Executa localmente via **Docker**
- Importa√ß√£o do `workflow.json` direto no n8n
- Uso do **LM Studio** (modelo local via `host.docker.internal:<PORTA>`)
- Padr√£o de leitura recursiva `**/*.py`
- Gera√ß√£o de documenta√ß√£o em Markdown (t√≠tulos, listas, trechos de c√≥digo)

## ‚úÖ Pr√©-requisitos
- **Docker** instalado
- **Git dentro do container do n8n** (para `git clone`)
- **Uma API de IA** (escolha uma):
  - **Groq** (externa), ou
  - **LM Studio** (local, compat√≠vel com OpenAI), ou
  - **OpenAI** (externa)

---

## üõ†Ô∏è Como correr na sua m√°quina (Windows)

### 1) Criar o container do n8n pelo terminal do computador (windows)

`docker run -it --name <CONTAINER_NAME> ^
  -v <HOST_PATH_TO_DATA>:/data ^
  -p <HOST_PORT>:5678 ^
  -e N8N_BASIC_AUTH_ACTIVE=true ^
  -e N8N_BASIC_AUTH_USER=<BASIC_AUTH_USER> ^
  -e N8N_BASIC_AUTH_PASSWORD=<BASIC_AUTH_PASSWORD> ^
  <IMAGE_NAME>`

### 2) Baixe o arquivo **workflow.json** que est√° neste reposit√≥rio

### 3) Acesse o n8n 

Abra: http://localhost:5679
  
### 4) Importar o workflow

No n8n, v√° em: **Create wokflow ‚Üí Import from file ‚Üí Selecione o ** `workflow.json`.

# ‚öôÔ∏è Como configurar o fluxo no n8n

## 1) N√≥ **Clonar reposit√≥rio** 

`rm -rf <TARGET_DIR> && git clone <REPO_URL> <TARGET_DIR>`

`<TARGET_DIR>`: a pasta de destino local onde o reposit√≥rio ser√° clonado.
Ex.: no container do n8n normalmente √© /data/repos.

`<REPO_URL>`: a URL do reposit√≥rio Git (HTTPS ou SSH).

Exemplo Completo:
`rm -rf /data/repos && git clone https://github.com/usuario/meu-repo.git /data/repos`

## 2) N√≥ **Ler Arquivos do c√≥digo**

Percorre os arquivos na pasta indicada e pega os arquivos na linguagem escolhida.

Exemplo:
`/data/repos/**/*.py`

`/data/repos/` ‚Üí pasta base onde a busca come√ßa.
`**/` ‚Üí percorre recursivamente zero ou mais subpastas.
`*.py` ‚Üí pega arquivos cujo nome termina em `py`

## 3) N√≥ **AI Agent**

Neste n√≥ podem ser usado dois tipos de APIs:

### **API Externa**: utiliza uma chave de API da OpenAI ou da Groq, obtida nas respetivas contas oficiais, para integrar o provedor externo ao teu fluxo conforme necess√°rio.
### **API Local**: 
### üì• Instalar o LM Studio

Baixe e instale para **Windows/macOS/Linux**:
- **LM Studio ‚Äî Download:** https://lmstudio.ai/download

### ‚¨áÔ∏è Baixar um modelo

No app, abra a aba de modelos (‚ÄúDiscover‚Äù), pesquise um modelo (ex.: llama-3.2-3b-instruct) clique em **Load**.  

### üîå Iniciar API local (OpenAI-compatible)

1. No LM Studio, v√° em **Developer / Start Server** (ou ‚ÄúLocal Server‚Äù).  

### üîó Conectar no n8n

Use o n√≥ **OpenAI Chat Model** (ou **OpenAI Compatible Chat**) e crie uma credencial com:
- **API Key:** `lm-studio`
- **Base URL:** `http://localhost:1234/v1` (ou `http://host.docker.internal:1234/v1` se o n8n estiver correndo em um container no Docker)
- **Model:** exatamente o nome exibido no LM Studio (ex.: `llama-3.2-3b-instruct`)

## 4) Ap√≥s isto, a documenta√ß√£o ser√° gerada e guardada na pasta indicada no n√≥ **Salvar DOCUMENTATION** 







